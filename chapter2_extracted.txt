Rozdział 2. Etyczny Kompas Nauczyciela w Erze AISekcja 2.1: Wprowadzenie do Etyki AI w SzkolePo zbudowaniu podstawowego zaufania i zrozumienia technologii, niezbędne jest natychmiastowe przejście do jej ram etycznych. To właśnie tutaj leżą najpoważniejsze obawy nauczycieli.1 Programy szkoleniowe muszą rezerwować dedykowany czas na omówienie etyki, w tym RODO, plagiatów, stronniczości (bias) i deepfake.1Technologia jest jedynie narzędziem. To nauczyciel pozostaje strażnikiem etyki, pedagogiki i bezpieczeństwa uczniów. Zrozumienie zagrożeń nie ma na celu odstraszenia od technologii, ale uzbrojenie nauczyciela w wiedzę i strategie, które pozwolą mu korzystać z AI w sposób świadomy, bezpieczny i odpowiedzialny.Sekcja 2.2: Warsztat Etyczny (Praktyczne Scenariusze)Teoria etyki jest bezużyteczna bez praktyki. Poniżej przedstawiamy cztery kluczowe wyzwania etyczne zidentyfikowane w programach szkoleniowych 1 i kompetencjach nauczycielskich 1, wraz z praktycznymi przykładami i rozwiązaniami kontekstowymi dla szkoły.Zagadnienie 1: RODO i Prywatność UczniówProblem: Nauczyciel chce użyć AI do analizy, oceny lub personalizacji pracy ucznia.Zagrożenie (Scenariusz): Nauczyciel Języka Polskiego jest zachwycony możliwościami ChatGPT. Kopiuje i wkleja wypracowanie ucznia na temat jego wakacji (zawierające jego imię, nazwisko, a być może i osobiste przemyślenia) do publicznej wersji ChatGPT z prośbą: "Oceń tę pracę i wskaż błędy". W tym momencie dane osobowe ucznia (imię, styl pisania, osobiste historie) opuszczają bezpieczny ekosystem szkoły. Mogą zostać wykorzystane do trenowania przyszłych modeli AI i są dostępne dla firmy obsługującej model. Jest to rażące naruszenie RODO (GDPR) i prawa do prywatności ucznia.Rozwiązanie (Praktyka):Zasada Anonimizacji: Podstawową zasadą jest nigdy nie wprowadzać żadnych danych identyfikujących uczniów (imion, nazwisk, nazw szkoły, adresów) do publicznych modeli AI. Jeśli nauczyciel chce przeanalizować tekst, musi go najpierw w pełni zanonimizować.Korzystanie z Kont Instytucjonalnych: Najbezpieczniejszym rozwiązaniem jest korzystanie z narzędzi AI oferowanych w ramach pakietów instytucjonalnych (np. Microsoft Copilot w ramach subskrypcji Microsoft 365 dla edukacji, Google Gemini w ramach Google Workspace for Education). Te wersje "enterprise" zazwyczaj oferują dodatkowe zabezpieczenia, w tym gwarancję, że dane wprowadzane przez użytkowników nie są wykorzystywane do trenowania modeli publicznych i pozostają w "piaskownicy" szkoły.Zagadnienie 2: Plagiat vs. Augmentacja (Filozofia 80/20)Problem: Uczeń oddaje pracę w całości wygenerowaną przez AI. Jest to jedna z głównych obaw nauczycieli (76%).1Zagrożenie (Scenariusz): Nauczyciel zadaje esej na temat przyczyn wybuchu I Wojny Światowej. Uczeń wpisuje temat w AI, kopiuje wygenerowany tekst i oddaje jako własny. Nauczyciel traci możliwość oceny rzeczywistej wiedzy i umiejętności ucznia.Wgląd i Rozwiązanie (Filozofia 80/20): Próba "zakazania" AI jest skazana na porażkę. Zamiast tego, skuteczne strategie pedagogiczne 1 proponują model "80/20".Filozofia 80/20 zakłada, że AI może być użyte do wygenerowania 80% "surowej" pracy (np. zebrania faktów, wstępnego szkicu, znalezienia argumentów), ale kluczowe 20% musi dodać człowiek (nauczyciel lub uczeń). To 20% to krytyczna analiza, weryfikacja faktów, dodanie własnej refleksji, unikalny styl i głębia.Rozwiązanie (Praktyka): Należy zmienić politykę klasową i projektowanie zadań domowych. Zamiast "Napisz esej o...", zadanie powinno brzmieć:"Użyj AI, aby wygenerować listę 5 głównych przyczyn wybuchu I Wojny Światowej." (80% pracy AI)"Wybierz dwie przyczyny, które uważasz za najważniejsze, i znajdź dla nich potwierdzenie w swoich źródłach (np. podręczniku)." (Weryfikacja)"Napisz dwa akapity własnej analizy, argumentując, dlaczego te dwie przyczyny były kluczowe, i jak się ze sobą łączyły." (20% pracy ucznia)"Dołącz wygenerowaną przez AI listę jako załącznik i zacytuj użyte narzędzie."W ten sposób zadanie przesuwa się z "pisania" na "myślenie", "weryfikowanie" i "redagowanie" – co jest znacznie cenniejszą kompetencją i bezpośrednią odpowiedzią na obawę o "zanik myślenia".Zagadnienie 4: Deepfake i DezinformacjaProblem: Uczniowie (i dorośli) mają coraz większy problem z odróżnieniem treści prawdziwych od fałszywych (deepfake audio/wideo, obrazy generowane przez AI).Zagrożenie (Scenariusz): W sieci krąży wideo, na którym znany polityk lub autorytet wygłasza kontrowersyjne opinie. Uczniowie przyjmują to za fakt, nie wiedząc, że to deepfake.Rozwiązanie (Praktyka): To jest kluczowa kompetencja medialna.1Nauka "Cyfrowej Intuicji": Ucz uczniów zwracania uwagi na nienaturalne detale. W przypadku obrazów AI (szczególnie starszych modeli) często są to: nienaturalnie wyglądające dłonie (za dużo lub za mało palców), dziwne artefakty w tle, nienaturalne cienie, "martwe" oczy. W przypadku wideo: brak mrugania, dziwne synchronizowanie ust, nienaturalna kadencja głosu.Gra "Prawda czy AI?": Zaimplementuj ćwiczenie z Modułu IV.1 Pokaż uczniom serię obrazów lub krótkich tekstów – niektóre prawdziwe, niektóre wygenerowane przez AI. Niech głosują i, co ważniejsze, uzasadniają, dlaczego uważają daną treść za prawdziwą lub fałszywą. To buduje ich umiejętności krytycznej analizy i weryfikacji.